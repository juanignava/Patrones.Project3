{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Load data from analysis dataset --\n",
    "\"\"\"\n",
    "\n",
    "parent_folder_path = \"images/analysis_dataset/\"\n",
    "\n",
    "categories = {}\n",
    "\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(parent_folder_path))):\n",
    "    folder_path = os.path.join(parent_folder_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "category_amount = []\n",
    "\n",
    "# get the category with the least images\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(parent_folder_path, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    category_amount.append(len(image_files))\n",
    "\n",
    "max_training = min(category_amount)\n",
    "\n",
    "arrays = []\n",
    "# convert the images into a pytorch dataset\n",
    "for cat_folder, value in categories.items():\n",
    "\n",
    "    folder_path = os.path.join(parent_folder_path, cat_folder)\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    for i, file_name in enumerate(image_files):\n",
    "\n",
    "        if i >= max_training: break\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # verify all images are of the desired size\n",
    "        if image.size != (100, 100):\n",
    "            print(file_path, \" IS NOT 250x250, it is: \", image.size)\n",
    "            continue\n",
    "\n",
    "        if image_array.shape != (250, 250):\n",
    "            image_array = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "        arrays.append(image_array)\n",
    "\n",
    "# Normalize the array of the normal \n",
    "arrays = arrays/ np.max(arrays)\n",
    "\n",
    "arrays_labels = []\n",
    "for i in range(len(categories)):\n",
    "    arrays_labels += [i] * max_training\n",
    "\n",
    "arrays_labels_normal = np.array(arrays_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Load autoencoder, train and testing data --\n",
    "\n",
    "Using the distribution:\n",
    "80% -> autoencoder\n",
    "10% -> training data\n",
    "10% -> testing data\n",
    "\"\"\"\n",
    "\n",
    "X_auto, X, y_auto, y = train_test_split(arrays, arrays_labels, test_size=0.5, random_state=42, stratify=arrays_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=38)\n",
    "y_test = to_categorical(y_test, num_classes=38)\n",
    "\n",
    "X_auto = np.array(X_auto)\n",
    "X_auto = X_auto.reshape((len(X_auto), -1))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape((len(X), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fit autoencoder\n",
      "Epoch 1/30\n",
      "86/86 [==============================] - 27s 292ms/step - loss: 0.6777 - val_loss: 0.6685\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 18s 208ms/step - loss: 0.6687 - val_loss: 0.6683\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 18s 207ms/step - loss: 0.6685 - val_loss: 0.6683\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 18s 208ms/step - loss: 0.6685 - val_loss: 0.6683\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 18s 208ms/step - loss: 0.6685 - val_loss: 0.6683\n",
      "Epoch 6/30\n",
      "60/86 [===================>..........] - ETA: 4s - loss: 0.6686"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBefore fit autoencoder\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Entrenar el autoencoder\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X_auto, X_auto,\n\u001b[0;32m     24\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m                 batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     27\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m(X, X))\n\u001b[0;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mafter autoencoder\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Obtener el vector latente (representaci√≥n codificada)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# definir la arquitectura del autoencoder\n",
    "\n",
    "input_img = Input(shape=(10000,))\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(400, activation='relu')(encoded)\n",
    "encoded = Dense(300, activation='relu')(encoded)\n",
    "latent = Dense(200, activation='relu')(encoded)\n",
    "encoded = Dense(300, activation='relu')(encoded)\n",
    "decoded = Dense(400, activation='relu')(latent)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(10000, activation='sigmoid')(decoded)\n",
    "\n",
    "# Crear el modelo del autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate = 0.01)\n",
    "autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "print(\"Before fit autoencoder\")\n",
    "\n",
    "# Entrenar el autoencoder\n",
    "autoencoder.fit(X_auto, X_auto,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X, X))\n",
    "\n",
    "print(\"after autoencoder\")\n",
    "# Obtener el vector latente (representaci√≥n codificada)\n",
    "encoder = Model(input_img, latent)\n",
    "encoded_train = encoder.predict(X_train)\n",
    "encoded_test = encoder.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "73/73 [==============================] - 2s 11ms/step - loss: 3.6411 - accuracy: 0.0263 - val_loss: 3.6407 - val_accuracy: 0.0262\n",
      "Epoch 2/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6406 - accuracy: 0.0263 - val_loss: 3.6403 - val_accuracy: 0.0262\n",
      "Epoch 3/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6403 - accuracy: 0.0263 - val_loss: 3.6400 - val_accuracy: 0.0262\n",
      "Epoch 4/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6400 - accuracy: 0.0263 - val_loss: 3.6397 - val_accuracy: 0.0262\n",
      "Epoch 5/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6397 - accuracy: 0.0263 - val_loss: 3.6395 - val_accuracy: 0.0262\n",
      "Epoch 6/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6394 - accuracy: 0.0263 - val_loss: 3.6392 - val_accuracy: 0.0262\n",
      "Epoch 7/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6392 - accuracy: 0.0263 - val_loss: 3.6390 - val_accuracy: 0.0262\n",
      "Epoch 8/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6390 - accuracy: 0.0263 - val_loss: 3.6389 - val_accuracy: 0.0262\n",
      "Epoch 9/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6389 - accuracy: 0.0263 - val_loss: 3.6387 - val_accuracy: 0.0262\n",
      "Epoch 10/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6387 - accuracy: 0.0263 - val_loss: 3.6386 - val_accuracy: 0.0262\n",
      "Epoch 11/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6386 - accuracy: 0.0263 - val_loss: 3.6384 - val_accuracy: 0.0262\n",
      "Epoch 12/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6385 - accuracy: 0.0263 - val_loss: 3.6383 - val_accuracy: 0.0262\n",
      "Epoch 13/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6384 - accuracy: 0.0263 - val_loss: 3.6383 - val_accuracy: 0.0262\n",
      "Epoch 14/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6383 - accuracy: 0.0263 - val_loss: 3.6382 - val_accuracy: 0.0262\n",
      "Epoch 15/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6382 - accuracy: 0.0263 - val_loss: 3.6381 - val_accuracy: 0.0262\n",
      "Epoch 16/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6381 - accuracy: 0.0263 - val_loss: 3.6380 - val_accuracy: 0.0262\n",
      "Epoch 17/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6381 - accuracy: 0.0263 - val_loss: 3.6380 - val_accuracy: 0.0262\n",
      "Epoch 18/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6380 - accuracy: 0.0263 - val_loss: 3.6379 - val_accuracy: 0.0262\n",
      "Epoch 19/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6380 - accuracy: 0.0263 - val_loss: 3.6379 - val_accuracy: 0.0262\n",
      "Epoch 20/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6379 - accuracy: 0.0263 - val_loss: 3.6378 - val_accuracy: 0.0262\n",
      "Epoch 21/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6379 - accuracy: 0.0263 - val_loss: 3.6378 - val_accuracy: 0.0262\n",
      "Epoch 22/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6379 - accuracy: 0.0263 - val_loss: 3.6378 - val_accuracy: 0.0262\n",
      "Epoch 23/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6378 - accuracy: 0.0263 - val_loss: 3.6378 - val_accuracy: 0.0262\n",
      "Epoch 24/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6378 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 25/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6378 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 26/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6378 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 27/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6378 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 28/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 29/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 30/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6377 - val_accuracy: 0.0262\n",
      "Epoch 31/200\n",
      "73/73 [==============================] - 0s 7ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 32/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0247 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 33/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0253 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 34/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 35/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 36/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0252 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 37/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6377 - accuracy: 0.0247 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 38/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 39/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 40/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 41/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 42/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6377 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 43/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 44/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 45/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0255 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 46/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 47/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 48/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 49/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 50/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 51/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 52/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 53/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 54/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 55/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 56/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0251 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 57/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0251 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 58/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 59/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0243 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 60/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0237 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 61/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0255 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 62/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0263 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 63/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0252 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 64/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0242 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 65/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0261 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 66/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0260 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 67/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0248 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 68/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0240 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 69/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0243 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 70/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0255 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 71/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0233 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 72/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0256 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 73/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0257 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 74/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0241 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 75/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0243 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 76/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0256 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 77/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0228 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 78/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0237 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 79/200\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 3.6376 - accuracy: 0.0234 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 80/200\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3.6376 - accuracy: 0.0248 - val_loss: 3.6376 - val_accuracy: 0.0262\n",
      "Epoch 81/200\n",
      "66/73 [==========================>...] - ETA: 0s - loss: 3.6376 - accuracy: 0.0236"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m classifier\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[39m# Entrenar el clasificador utilizando el vector latente como caracter√≠sticas de entrada\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(encoded_train, y_train,\n\u001b[0;32m     16\u001b[0m                epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[0;32m     17\u001b[0m                batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m                validation_data\u001b[39m=\u001b[39;49m(encoded_test, y_test), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Evaluar el rendimiento del clasificador en el conjunto de prueba\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss, accuracy \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mevaluate(encoded_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1728\u001b[0m     )\n\u001b[1;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1741\u001b[0m )\n\u001b[0;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m }\n\u001b[0;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2070\u001b[0m ):\n\u001b[0;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Juan Navarro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Definir la arquitectura del clasificador utilizando el vector latente como entrada\n",
    "input_latent = Input(shape=(200,))\n",
    "output = Dense(128, activation='softmax')(input_latent)\n",
    "output = Dense(64, activation='softmax')(input_latent)\n",
    "output = Dense(38, activation='softmax')(input_latent)\n",
    "\n",
    "# Crear el modelo del clasificador\n",
    "classifier = Model(input_latent, output)\n",
    "\n",
    "# Compilar el modelo del clasificador\n",
    "optimizer = Adam(learning_rate = 0.0001)\n",
    "classifier.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el clasificador utilizando el vector latente como caracter√≠sticas de entrada\n",
    "classifier.fit(encoded_train, y_train,\n",
    "               epochs=200,\n",
    "               batch_size=256,\n",
    "               validation_data=(encoded_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluar el rendimiento del clasificador en el conjunto de prueba\n",
    "loss, accuracy = classifier.evaluate(encoded_test, y_test)\n",
    "print(\"P√©rdida de clasificaci√≥n:\", loss)\n",
    "print(\"Exactitud de clasificaci√≥n:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
