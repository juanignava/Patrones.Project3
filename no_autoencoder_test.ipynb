{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio que contiene las imágenes\n",
    "image_directory = \"images/resized_dataset/\"\n",
    "\n",
    "# Inicializar una lista vacía para almacenar las imágenes\n",
    "images = []\n",
    "images_test = []\n",
    "\n",
    "# Tamaño del lote\n",
    "batch_size = 100\n",
    "\n",
    "# Recorrer las subcarpetas dentro del directorio\n",
    "for root, dirs, files in os.walk(image_directory):\n",
    "    for directory in dirs:\n",
    "        subdir = os.path.join(root, directory)\n",
    "        # Obtener la lista de nombres de archivo de las imágenes en la subcarpeta\n",
    "        image_files = os.listdir(subdir)\n",
    "        # Procesar las imágenes en lotes\n",
    "        total = len(image_files)\n",
    "        porcentaje = 80\n",
    "        entrenamiento = int((total/100)*porcentaje)\n",
    "        prueba = int(total - entrenamiento)\n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            # Cargar y convertir las imágenes en matrices numpy para entrenamiento\n",
    "            if (i <= entrenamiento):\n",
    "                batch_images = []\n",
    "                for file in image_files[i:i+batch_size]:\n",
    "                    image_path = os.path.join(subdir, file)\n",
    "                    image = Image.open(image_path)\n",
    "                    image_array = np.array(image)\n",
    "                    batch_images.append(image_array)\n",
    "                \n",
    "                # Concatenar las matrices del lote en un solo array\n",
    "                batch_X = np.concatenate(batch_images)\n",
    "                images.append(batch_X)\n",
    "            else:\n",
    "                # Cargar y convertir las imágenes en matrices numpy para pruebas\n",
    "                batch_images_test = []\n",
    "                for file in image_files[i:i+batch_size]:\n",
    "                    image_path = os.path.join(subdir, file)\n",
    "                    image = Image.open(image_path)\n",
    "                    image_array = np.array(image)\n",
    "                    batch_images_test.append(image_array)\n",
    "                \n",
    "                # Concatenar las matrices del lote en un solo array\n",
    "                batch_X_test = np.concatenate(batch_images_test)\n",
    "                images_test.append(batch_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[104. 151.  49. 104. 151.  49. 106. 151.  50. 109. 154.  53. 111. 156.\n",
      "  55. 107. 152.  51. 101. 143.  41.  94. 136.  34. 104. 147.  42. 112.\n",
      " 155.  50. 114. 155.  51. 103. 144.  40.  96. 137.  31. 100. 141.  35.\n",
      " 110. 151.  45. 115. 158.  50.  96. 143.  27.  97. 146.  28.  98. 147.\n",
      "  32.  94. 142.  30.  88. 136.  26.  87. 134.  28.  91. 136.  35.  95.\n",
      " 139.  42.  93. 134.  42. 103. 143.  55. 111. 151.  65. 109. 148.  65.\n",
      " 104. 141.  61. 102. 139.  59. 106. 143.  65. 109. 146.  66. 100. 137.\n",
      "  57.  97. 135.  52.  95. 133.  48.  98. 136.  51. 104. 142.  57. 110.\n",
      " 148.  63. 113. 151.  64. 114. 152.  65. 123. 161.  74. 114. 152.  65.\n",
      " 103. 142.  53.  97. 136.  47.  98. 137.  48. 101. 140.  51. 101. 140.\n",
      "  51. 100. 139.  50. 103. 138.  48. 106. 141.  51. 106. 141.  51. 104.\n",
      " 139.  49. 102. 136.  49. 100. 134.  47.  93. 127.  41.  84. 118.  32.\n",
      "  83. 117.  33.  77. 111.  27.  71. 104.  23.  68. 101.  20.  71. 104.\n",
      "  23.  76. 109.  28.  78. 111.  32.  78. 111.  32.], shape=(192,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Concatenar los lotes en un solo array\n",
    "X_train = np.concatenate(images)\n",
    "X_test = np.concatenate(images_test)\n",
    "\n",
    "# Aplanar las matrices de imágenes a un formato bidimensional\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Convertir las imágenes a tensores\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "\n",
    "# Normalizar los datos de entrenamiento y prueba utilizando normalización min-max\n",
    "#X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "#X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jose David\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 31 20 ... 11 16 11]\n",
      "[19 19 19 ... 36 36 36]\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo K-Means para generar etiquetas de clúster\n",
    "kmeans = KMeans(n_clusters=38)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Obtener las etiquetas de clúster asignadas a los puntos de datos\n",
    "labels_train = kmeans.labels_\n",
    "print(labels_train)\n",
    "labels_test = kmeans.predict(X_test)\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n",
      "Epoch 1/5\n",
      "1434/1434 [==============================] - 5s 3ms/step - loss: 117.1872 - accuracy: 0.0215\n",
      "Epoch 2/5\n",
      "1434/1434 [==============================] - 5s 3ms/step - loss: 117.1872 - accuracy: 0.0221\n",
      "Epoch 3/5\n",
      "1434/1434 [==============================] - 5s 3ms/step - loss: 117.1872 - accuracy: 0.0257\n",
      "Epoch 4/5\n",
      "1434/1434 [==============================] - 5s 3ms/step - loss: 117.1870 - accuracy: 0.0265\n",
      "Epoch 5/5\n",
      "1434/1434 [==============================] - 5s 3ms/step - loss: 117.1872 - accuracy: 0.0257\n",
      "91750/91750 [==============================] - 50s 546us/step\n",
      "17858/17858 [==============================] - 10s 536us/step\n",
      "[[0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " ...\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.02612459 0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.02612459 0.02635355 ... 0.02630159 0.02631099 0.02629538]]\n",
      "[[0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " ...\n",
      " [0.02630265 0.0261246  0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.02612459 0.02635355 ... 0.02630159 0.02631099 0.02629538]\n",
      " [0.02630265 0.02612459 0.02635355 ... 0.02630159 0.02631099 0.02629538]]\n"
     ]
    }
   ],
   "source": [
    "# Definir la función de pérdida para el clustering K-Means\n",
    "def kmeans_loss(y_true, y_pred):\n",
    "    if y_true.dtype != tf.float32:\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "    if y_pred.dtype != tf.float32:\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "    return tf.norm(y_pred - y_true, axis=1)\n",
    "\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.maximum(tf.minimum(y_pred, 1 - 1e-15), 1e-15)  # Asegurar valores en el rango (epsilon, 1-epsilon) para evitar log(0)\n",
    "    return -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "\n",
    "# Definir el modelo K-Means con una capa oculta\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)\n",
    "model_input = layers.Input(shape=input_shape)\n",
    "hidden_layer = layers.Dense(units=64, activation='sigmoid')(model_input) \n",
    "kmeans_output = layers.Dense(units=38, activation='softmax')(hidden_layer)\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate = 0.01)\n",
    "model = Model(inputs=model_input, outputs=kmeans_output)\n",
    "model.compile(optimizer=optimizer, loss=kmeans_loss, metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo utilizando las etiquetas de clúster generadas\n",
    "model.fit(X_train, labels_train, epochs=5, batch_size=2048)\n",
    "\n",
    "# Obtener las etiquetas de clúster asignadas a los puntos de datos\n",
    "labels_pred_train = model.predict(X_train)\n",
    "labels_pred_test = model.predict(X_test)\n",
    "\n",
    "# Imprimir las etiquetas de clúster\n",
    "print(labels_pred_train)\n",
    "print(labels_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:12:34,234] A new study created in memory with name: no-name-f4274951-3002-4d7d-b57a-8ace25ed0545\n",
      "C:\\Users\\Jose David\\AppData\\Local\\Temp\\ipykernel_1072\\1011583943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 0.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 11s 635us/step - loss: 117.6831 - accuracy: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:13:25,144] Trial 0 finished with value: 0.019291074946522713 and parameters: {'learning_rate': 0.1711939257602313, 'epochs': 8}. Best is trial 0 with value: 0.019291074946522713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 640us/step - loss: 117.6635 - accuracy: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:14:14,137] Trial 1 finished with value: 0.018440615385770798 and parameters: {'learning_rate': 0.012619017638839531, 'epochs': 9}. Best is trial 0 with value: 0.019291074946522713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 650us/step - loss: 117.6831 - accuracy: 0.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:14:50,975] Trial 2 finished with value: 0.04489409551024437 and parameters: {'learning_rate': 0.21385921042323788, 'epochs': 6}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 11s 637us/step - loss: 117.6635 - accuracy: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:15:23,440] Trial 3 finished with value: 0.02467031590640545 and parameters: {'learning_rate': 0.001035603556659793, 'epochs': 5}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 640us/step - loss: 117.6635 - accuracy: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:16:08,056] Trial 4 finished with value: 0.012119918130338192 and parameters: {'learning_rate': 0.004813226074917951, 'epochs': 8}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 648us/step - loss: 117.6831 - accuracy: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:16:40,516] Trial 5 finished with value: 0.014484054408967495 and parameters: {'learning_rate': 0.1750915567814973, 'epochs': 5}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 648us/step - loss: 117.6831 - accuracy: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:17:32,833] Trial 6 finished with value: 0.02074175514280796 and parameters: {'learning_rate': 0.48927072802758714, 'epochs': 10}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 648us/step - loss: 117.6635 - accuracy: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:18:05,386] Trial 7 finished with value: 0.005877967923879623 and parameters: {'learning_rate': 0.02295807318934476, 'epochs': 5}. Best is trial 2 with value: 0.04489409551024437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 649us/step - loss: 117.6635 - accuracy: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:18:53,371] Trial 8 finished with value: 0.060683585703372955 and parameters: {'learning_rate': 0.001884264720655518, 'epochs': 9}. Best is trial 8 with value: 0.060683585703372955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17858/17858 [==============================] - 12s 645us/step - loss: 117.6831 - accuracy: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 08:19:29,444] Trial 9 finished with value: 0.018101131543517113 and parameters: {'learning_rate': 0.06594596931567717, 'epochs': 6}. Best is trial 8 with value: 0.060683585703372955.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de accuracy: 0.060683585703372955\n",
      "Mejores hiperparámetros: {'learning_rate': 0.001884264720655518, 'epochs': 9}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda para los hiperparámetros\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.001, 0.9)\n",
    "    epochs = trial.suggest_int('epochs', 5, 10)\n",
    "    \n",
    "    # Definir el modelo K-Means con una capa oculta\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model_input = layers.Input(shape=input_shape)\n",
    "    hidden_layer = layers.Dense(units=64, activation='sigmoid')(model_input) \n",
    "    kmeans_output = layers.Dense(units=38, activation='softmax')(hidden_layer)\n",
    "    \n",
    "    # Compilar el modelo con los hiperparámetros sugeridos\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model = Model(inputs=model_input, outputs=kmeans_output)\n",
    "    model.compile(optimizer=optimizer, loss=kmeans_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Entrenar el modelo utilizando las etiquetas de clúster generadas\n",
    "    model.fit(X_train, labels_train, epochs=epochs, batch_size=2048, verbose=0)\n",
    "    \n",
    "    # Evaluar el modelo en los datos de prueba\n",
    "    accuracy = model.evaluate(X_test, labels_test)[1]\n",
    "    \n",
    "    # Devolver el valor de métrica a optimizar (precisión en este caso)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=False)\n",
    "\n",
    "# Imprimir los mejores valores encontrados\n",
    "print('Mejor valor de accuracy:', study.best_value)\n",
    "print('Mejores hiperparámetros:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de accuracy: 0.11121363937854767\n",
      "Mejores hiperparámetros: {'learning_rate': 0.005726461916546583, 'epochs': 9}\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los mejores valores encontrados\n",
    "print('Mejor valor de accuracy:', study.best_value)\n",
    "print('Mejores hiperparámetros:', study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
