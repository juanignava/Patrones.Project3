{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 3 - Aprendizaje no supervisado\n",
    "\n",
    "- Juan Ignacio Navarro\n",
    "- Jose David SÃ¡nchez\n",
    "- Steven Badilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Used libraries for the entire project\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random \n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set de datos llamado Plant_leaf_deseases_dataset_without_augmentation: https://data.mendeley.com/datasets/tywbtsjrjv/1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and fix Bias in images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Delete unnecessary images --\n",
    "\n",
    "These background images do not help the model on anything\n",
    "\"\"\"\n",
    "\n",
    "os.remove(\"images/original_dataset/Background_without_leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Delete images from cropped dataset --\n",
    "\n",
    "This cell deletes the files in the cropped dataset if any. The\n",
    "cropped dataset a cropped copy from the additional dataset images.\n",
    "The images are cropped to show only the most important part of \n",
    "the leaves which is the center\n",
    "\"\"\"\n",
    "\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "\n",
    "# get the categories\n",
    "categories = {}\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    folder_path = os.path.join(cropped_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# remove the files\n",
    "for category in categories.keys():\n",
    "\n",
    "    folder_path = os.path.join(cropped_images_folder, category)\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(cropped_images_folder, category, file_name)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Crop images borders -- \n",
    "\n",
    "This block crops the images borders and saves the new images into the cropped_dataset\n",
    "\"\"\"\n",
    "\n",
    "# define a different folder to save the cropped images\n",
    "original_images_folder = 'images/original_dataset/'\n",
    "analysis_images_folder = 'images/cropped_dataset/'\n",
    "\n",
    "# define the new size\n",
    "target_size = (100, 100)\n",
    "\n",
    "categories = {}\n",
    "\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(original_images_folder))):\n",
    "    folder_path = os.path.join(original_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# Create category folders in cropped dataset\n",
    "for index, folder_name in enumerate(sorted(os.listdir(original_images_folder))):\n",
    "    folder_path = os.path.join(cropped_images_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# crop and save the cropped images\n",
    "for category in categories.keys():\n",
    "\n",
    "    cat_files = os.listdir(os.path.join(original_images_folder, category))\n",
    "\n",
    "    for i, file in enumerate(cat_files):\n",
    "\n",
    "        # constructing image path\n",
    "        input_path = os.path.join(original_images_folder, category, file)\n",
    "        image = Image.open(input_path)\n",
    "\n",
    "        if image.size[0] < 256 or image.size[1] < 256:\n",
    "            continue\n",
    "        \n",
    "        # get original image size and calculate borders\n",
    "        width, height = image.size\n",
    "        left = (width - target_size[0]) // 2\n",
    "        upper = (height - target_size[1]) // 2\n",
    "        right = left + target_size[0]\n",
    "        lower = upper + target_size[1]\n",
    "\n",
    "        # crop the image\n",
    "        cropped_image = image.crop((left, upper, right, lower))\n",
    "        output_path = os.path.join(cropped_images_folder, category, file)\n",
    "        cropped_image.save(output_path)\n",
    "        image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of images in analysis dataset:\n",
      "Apple___Apple_scab                                :   630\n",
      "Apple___Black_rot                                 :   621\n",
      "Apple___Cedar_apple_rust                          :   275\n",
      "Apple___healthy                                   :  1645\n",
      "Blueberry___healthy                               :  1502\n",
      "Cherry___Powdery_mildew                           :  1052\n",
      "Cherry___healthy                                  :   854\n",
      "Corn___Cercospora_leaf_spot Gray_leaf_spot        :   513\n",
      "Corn___Common_rust                                :  1192\n",
      "Corn___Northern_Leaf_Blight                       :   985\n",
      "Corn___healthy                                    :  1162\n",
      "Grape___Black_rot                                 :  1180\n",
      "Grape___Esca_(Black_Measles)                      :  1383\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)        :  1076\n",
      "Grape___healthy                                   :   423\n",
      "Orange___Haunglongbing_(Citrus_greening)          :  5507\n",
      "Peach___Bacterial_spot                            :  2297\n",
      "Peach___healthy                                   :   360\n",
      "Pepper,_bell___Bacterial_spot                     :   997\n",
      "Pepper,_bell___healthy                            :  1477\n",
      "Potato___Early_blight                             :  1000\n",
      "Potato___Late_blight                              :  1000\n",
      "Potato___healthy                                  :   152\n",
      "Raspberry___healthy                               :   371\n",
      "Soybean___healthy                                 :  5090\n",
      "Squash___Powdery_mildew                           :  1835\n",
      "Strawberry___Leaf_scorch                          :  1109\n",
      "Strawberry___healthy                              :   456\n",
      "Tomato___Bacterial_spot                           :  2127\n",
      "Tomato___Early_blight                             :  1000\n",
      "Tomato___Late_blight                              :  1909\n",
      "Tomato___Leaf_Mold                                :   952\n",
      "Tomato___Septoria_leaf_spot                       :  1771\n",
      "Tomato___Spider_mites Two-spotted_spider_mite     :  1676\n",
      "Tomato___Target_Spot                              :  1404\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus            :  5357\n",
      "Tomato___Tomato_mosaic_virus                      :   373\n",
      "Tomato___healthy                                  :  1591\n",
      "Category with the minimum amount of images: Potato___healthy with 152\n",
      "Category with the maximim amount of images: Orange___Haunglongbing_(Citrus_greening) with 5507\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Check Bias --\n",
    "\n",
    "Calculate the amount of images to check for possible Bias in the dataset\n",
    "\"\"\"\n",
    "\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "category_amount = []\n",
    "min_bias = 10e4\n",
    "min_bias_key = ''\n",
    "max_bias = 0\n",
    "max_bias_key = ''\n",
    "\n",
    "categories = {}\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    folder_path = os.path.join(cropped_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# get the amount of images for each category\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(cropped_images_folder, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    folder_count = len(image_files)\n",
    "    if folder_count > max_bias:\n",
    "        max_bias = folder_count\n",
    "        max_bias_key = category\n",
    "    if folder_count < min_bias:\n",
    "        min_bias = folder_count\n",
    "        min_bias_key = category\n",
    "    category_amount.append(folder_count)\n",
    "\n",
    "# Print the information taken\n",
    "print(\"Amount of images in analysis dataset:\")\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    print(f\"{folder_name:50}: {category_amount[index]:5d}\")\n",
    "\n",
    "print(f\"Category with the minimum amount of images: {min_bias_key} with {min_bias}\")\n",
    "print(f\"Category with the maximim amount of images: {max_bias_key} with {max_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Eliminate bias by combining images --\n",
    "\n",
    "By combining pixels from the images categories it will be possible to add more images to the categories\n",
    "that need more data\n",
    "\"\"\"\n",
    "\n",
    "cropped_dataset_folder = \"images/cropped_dataset/\"\n",
    "\n",
    "max_bias_folder = f\"{cropped_dataset_folder}/{max_bias_key}/\"\n",
    "\n",
    "AMOUNT_IMAGES = 500   \n",
    "\n",
    "folders = os.listdir(cropped_dataset_folder)\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(cropped_dataset_folder, folder)\n",
    "    amount_images = len(os.listdir(folder_path))\n",
    "\n",
    "    if amount_images > 1.5 * min_bias: continue\n",
    "\n",
    "    random_images = random.sample(os.listdir(folder_path), min_bias)\n",
    "\n",
    "    counter = 0\n",
    "    counter_random = 0\n",
    "    while(counter < AMOUNT_IMAGES):\n",
    "\n",
    "        for image in os.listdir(folder_path):\n",
    "\n",
    "            if counter % min_bias == 0: counter_random += 1\n",
    "\n",
    "            if (counter == AMOUNT_IMAGES): break\n",
    "            random_image_path = os.path.join(max_bias_folder, random_images[counter_random])\n",
    "            other_folder_image_path = os.path.join(folder_path, image)\n",
    "\n",
    "            image1 = Image.open(random_image_path)\n",
    "            image2 = Image.open(other_folder_image_path)\n",
    "\n",
    "            if image1.size == (100, 100, 3) or image2.size == (100, 100, 3): continue\n",
    "\n",
    "            image1.resize((100, 100))\n",
    "            image2.resize((100, 100))\n",
    "\n",
    "            array1 = np.array(image1)\n",
    "            array2 = np.array(image2)\n",
    "\n",
    "            average_array = (0.5 * array1 + 0.5 * array2).astype(np.uint8)\n",
    "            combined_image = Image.fromarray(average_array)\n",
    "            \n",
    "            combined_image_path = os.path.join(folder_path, f\"combined_{counter}.JPG\")\n",
    "            combined_image.save(combined_image_path)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of images in analysis dataset:\n",
      "Apple___Apple_scab                                :   630\n",
      "Apple___Black_rot                                 :   621\n",
      "Apple___Cedar_apple_rust                          :   775\n",
      "Apple___healthy                                   :  1645\n",
      "Blueberry___healthy                               :  1502\n",
      "Cherry___Powdery_mildew                           :  1052\n",
      "Cherry___healthy                                  :   854\n",
      "Corn___Cercospora_leaf_spot Gray_leaf_spot        :   513\n",
      "Corn___Common_rust                                :  1192\n",
      "Corn___Northern_Leaf_Blight                       :   985\n",
      "Corn___healthy                                    :  1162\n",
      "Grape___Black_rot                                 :  1180\n",
      "Grape___Esca_(Black_Measles)                      :  1383\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)        :  1076\n",
      "Grape___healthy                                   :   423\n",
      "Orange___Haunglongbing_(Citrus_greening)          :  5507\n",
      "Peach___Bacterial_spot                            :  2297\n",
      "Peach___healthy                                   :   860\n",
      "Pepper,_bell___Bacterial_spot                     :   997\n",
      "Pepper,_bell___healthy                            :  1477\n",
      "Potato___Early_blight                             :  1000\n",
      "Potato___Late_blight                              :  1000\n",
      "Potato___healthy                                  :   652\n",
      "Raspberry___healthy                               :   871\n",
      "Soybean___healthy                                 :  5090\n",
      "Squash___Powdery_mildew                           :  1835\n",
      "Strawberry___Leaf_scorch                          :  1109\n",
      "Strawberry___healthy                              :   456\n",
      "Tomato___Bacterial_spot                           :  2127\n",
      "Tomato___Early_blight                             :  1000\n",
      "Tomato___Late_blight                              :  1909\n",
      "Tomato___Leaf_Mold                                :   952\n",
      "Tomato___Septoria_leaf_spot                       :  1771\n",
      "Tomato___Spider_mites Two-spotted_spider_mite     :  1676\n",
      "Tomato___Target_Spot                              :  1404\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus            :  5357\n",
      "Tomato___Tomato_mosaic_virus                      :   873\n",
      "Tomato___healthy                                  :  1591\n",
      "Category with the minimum amount of images: Grape___healthy with 423\n",
      "Category with the maximim amount of images: Orange___Haunglongbing_(Citrus_greening) with 5507\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Check Bias --\n",
    "\n",
    "Calculate the amount of images to check for possible Bias in the dataset\n",
    "\"\"\"\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "category_amount = []\n",
    "min_bias = 10e4\n",
    "min_bias_key = ''\n",
    "max_bias = 0\n",
    "max_bias_key = ''\n",
    "\n",
    "categories = {}\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    folder_path = os.path.join(cropped_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# get the amount of images for each category\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(cropped_images_folder, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    folder_count = len(image_files)\n",
    "    if folder_count > max_bias:\n",
    "        max_bias = folder_count\n",
    "        max_bias_key = category\n",
    "    if folder_count < min_bias:\n",
    "        min_bias = folder_count\n",
    "        min_bias_key = category\n",
    "    category_amount.append(folder_count)\n",
    "\n",
    "# Print the information taken\n",
    "print(\"Amount of images in analysis dataset:\")\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    print(f\"{folder_name:50}: {category_amount[index]:5d}\")\n",
    "\n",
    "print(f\"Category with the minimum amount of images: {min_bias_key} with {min_bias}\")\n",
    "print(f\"Category with the maximim amount of images: {max_bias_key} with {max_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Delete images from analysis dataset --\n",
    "\n",
    "This cell deletes the files in the cropped dataset if any. The\n",
    "cropped dataset a cropped copy from the additional dataset images.\n",
    "The images are cropped to show only the most important part of \n",
    "the leaves which is the center\n",
    "\"\"\"\n",
    "\n",
    "analysis_images_folder = 'images/analysis_dataset/'\n",
    "\n",
    "# get the categories\n",
    "categories = {}\n",
    "for index, folder_name in enumerate(sorted(os.listdir(analysis_images_folder))):\n",
    "    folder_path = os.path.join(analysis_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# remove the files\n",
    "for category in categories.keys():\n",
    "\n",
    "    folder_path = os.path.join(analysis_images_folder, category)\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(analysis_images_folder, category, file_name)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Move images to analysis dataset --\n",
    "\n",
    "This ignores the extra images in the Bias\n",
    "\"\"\"\n",
    "\n",
    "# define a different folder to save the cropped images\n",
    "analysis_images_folder = 'images/analysis_dataset/'\n",
    "cropped_images_folder = 'images/cropped_dataset/'\n",
    "\n",
    "categories = {}\n",
    "\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    folder_path = os.path.join(cropped_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# Create category folders in cropped dataset\n",
    "for index, folder_name in enumerate(sorted(os.listdir(cropped_images_folder))):\n",
    "    folder_path = os.path.join(analysis_images_folder, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "for category in categories.keys():\n",
    "\n",
    "    cropped_category_folder = os.path.join(cropped_images_folder, category)\n",
    "    analysis_category_folder = os.path.join(analysis_images_folder, category)\n",
    "\n",
    "    for i, image in enumerate(os.listdir(cropped_category_folder)[::-1]):\n",
    "\n",
    "        #if i == min_bias*1.5: break\n",
    "\n",
    "        cropped_image_path = os.path.join(cropped_category_folder, image)\n",
    "        analysis_image_path = os.path.join(analysis_category_folder, image)\n",
    "\n",
    "        shutil.copy(cropped_image_path, analysis_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category with the minimum amount of images: Potato___healthy with 152\n",
      "Category with the maximim amount of images: Orange___Haunglongbing_(Citrus_greening) with 5507\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-- Check Bias --\n",
    "\n",
    "Calculate the amount of images to check for possible Bias in the dataset\n",
    "\"\"\"\n",
    "\n",
    "analysis_images_folder = 'images/analysis_dataset/'\n",
    "category_amount = []\n",
    "min_bias = 10e4\n",
    "min_bias_key = ''\n",
    "max_bias = 0\n",
    "max_bias_key = ''\n",
    "\n",
    "categories = {}\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(analysis_images_folder))):\n",
    "    folder_path = os.path.join(analysis_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# get the amount of images for each category\n",
    "for category in categories.keys():\n",
    "    folder_path = os.path.join(analysis_images_folder, category)\n",
    "    image_files = os.listdir(folder_path)\n",
    "    folder_count = len(image_files)\n",
    "    if folder_count > max_bias:\n",
    "        max_bias = folder_count\n",
    "        max_bias_key = category\n",
    "    if folder_count < min_bias:\n",
    "        min_bias = folder_count\n",
    "        min_bias_key = category\n",
    "    category_amount.append(folder_count)\n",
    "\n",
    "print(f\"Category with the minimum amount of images: {min_bias_key} with {min_bias}\")\n",
    "print(f\"Category with the maximim amount of images: {max_bias_key} with {max_bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Delete contents in resized_dataset folder -- \n",
    "\"\"\"\n",
    "resized_images_folder = 'images/resized_dataset/'\n",
    "\n",
    "# get the categories\n",
    "categories = {}\n",
    "for index, folder_name in enumerate(sorted(os.listdir(resized_images_folder))):\n",
    "    folder_path = os.path.join(resized_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "# remove the files\n",
    "for category in categories.keys():\n",
    "\n",
    "    folder_path = os.path.join(resized_images_folder, category)\n",
    "    file_list = os.listdir(folder_path)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(resized_images_folder, category, file_name)\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Resize images to 64 x 64 --\n",
    "\"\"\"\n",
    "\n",
    "analysis_images_folder = 'images/analysis_dataset/'\n",
    "resized_images_folder = 'images/resized_dataset/'\n",
    "\n",
    "\n",
    "categories = {}\n",
    "# Iterate over the contents of the \"original_dataset\" folder\n",
    "for index, folder_name in enumerate(sorted(os.listdir(analysis_images_folder))):\n",
    "    folder_path = os.path.join(analysis_images_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        categories[folder_name] = index\n",
    "\n",
    "for category in categories.keys():\n",
    "\n",
    "    analysis_category_folder = os.path.join(analysis_images_folder, category)\n",
    "    resized_category_folder = os.path.join(resized_images_folder, category)\n",
    "\n",
    "    if not os.path.exists(resized_category_folder):\n",
    "        os.mkdir(resized_category_folder)\n",
    "\n",
    "    for image in os.listdir(analysis_category_folder):\n",
    "\n",
    "        analysis_image_path = os.path.join(analysis_category_folder, image)\n",
    "        resized_image_path = os.path.join(resized_category_folder, image)\n",
    "\n",
    "        desired_size = (64, 64)\n",
    "\n",
    "        image = Image.open(analysis_image_path)\n",
    "\n",
    "        resized_image = image.resize(desired_size)\n",
    "\n",
    "        resized_image.save(resized_image_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
